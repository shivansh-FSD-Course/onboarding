<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MAISA Onboarding Assistant</title>

  <!-- PDF.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>

  <!-- Mammoth.js for DOCX -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mammoth/1.6.0/mammoth.browser.min.js"></script>

  <!-- React (UMD) + Babel -->
  <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
  <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:wght@400;500;600&family=IBM+Plex+Mono:wght@400;500&display=swap" rel="stylesheet">

  <style>
    :root{
      --bg:#faf6f1; --panel:#f5ede4; --panel2:#efe5d8;
      --border:#d9c9b5; --text:#2c2416; --muted:#8c7a62;
      --accent:#b85c38; --accent2:#a04e2e;
      --ok:#5a8a5c; --warn:#c4883a; --err:#c25454; --info:#5a7a9a;
    }
    *{box-sizing:border-box;margin:0;padding:0}
    body{font-family:"Source Serif 4",Georgia,serif;background:var(--bg);color:var(--text);line-height:1.6}
    .app{display:grid;grid-template-columns:340px 1fr;min-height:100vh}
    .side{background:var(--panel);border-right:1px solid var(--border);padding:22px;overflow:auto}
    .main{display:flex;flex-direction:column;height:100vh}
    h1{font-size:20px;font-weight:600}
    .logo{display:flex;gap:12px;align-items:center;padding-bottom:16px;border-bottom:1px solid var(--border);margin-bottom:18px}
    .mark{width:44px;height:44px;border-radius:12px;display:flex;align-items:center;justify-content:center;color:#fff;font-weight:700;
      background:linear-gradient(135deg,var(--accent),#d4886a)}
    .sub{font-size:12px;color:var(--muted)}
    .sec{margin-top:18px}
    .secTitle{font-size:11px;letter-spacing:.08em;text-transform:uppercase;color:var(--muted);font-weight:700;margin-bottom:10px}
    label{font-size:13px;color:#5c4d3a}
    input,select,textarea,button{font:inherit}
    input[type="password"], input[type="text"], select{
      width:100%;padding:10px 12px;border:1px solid var(--border);border-radius:10px;background:#fff;
      font-family:"IBM Plex Mono",monospace;font-size:12px;color:var(--text)
    }
    textarea{width:100%;border:1px solid var(--border);border-radius:14px;padding:14px 16px;background:#fff;min-height:56px;resize:none}
    input:focus,select:focus,textarea:focus{outline:none;border-color:var(--accent);box-shadow:0 0 0 3px rgba(184,92,56,.15)}
    .btn{border:1px solid var(--border);background:var(--panel2);padding:10px 12px;border-radius:10px;cursor:pointer}
    .btn:hover{background:#e8dccb}
    .btnPrimary{background:var(--accent);border-color:var(--accent);color:#fff}
    .btnPrimary:hover{background:var(--accent2)}
    .btn:disabled{opacity:.55;cursor:not-allowed}
    .status{background:#fff;border:1px solid var(--border);border-radius:12px;padding:12px}
    .statusRow{display:flex;gap:10px;align-items:center}
    .dot{width:34px;height:34px;border-radius:999px;display:flex;align-items:center;justify-content:center;font-weight:700}
    .dot.ok{background:rgba(90,138,92,.15);color:var(--ok)}
    .dot.warn{background:rgba(196,136,58,.15);color:var(--warn)}
    .dot.err{background:rgba(194,84,84,.15);color:var(--err)}
    .dot.info{background:rgba(90,122,154,.15);color:var(--info)}
    .statusMsg{margin-left:44px;margin-top:6px;font-family:"IBM Plex Mono",monospace;font-size:11px;color:#5c4d3a;white-space:pre-line}
    .help{font-size:12px;color:var(--muted)}
    .help a{color:var(--accent);text-decoration:none}
    .help a:hover{text-decoration:underline}
    .drop{border:2px dashed var(--border);background:#fff;border-radius:14px;padding:18px;text-align:center;cursor:pointer}
    .drop:hover{border-color:var(--accent);background:rgba(184,92,56,.08)}
    .drop.disabled{opacity:.55;cursor:not-allowed}
    .list{display:flex;flex-direction:column;gap:8px;max-height:180px;overflow:auto}
    .item{background:#fff;border:1px solid var(--border);border-radius:10px;padding:10px 12px;display:flex;justify-content:space-between;align-items:center;font-size:12px}
    .item .name{max-width:170px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;font-weight:600}
    .item .meta{color:var(--muted);font-family:"IBM Plex Mono",monospace;font-size:11px}
    .x{border:none;background:transparent;color:var(--muted);cursor:pointer;padding:4px 8px;border-radius:8px}
    .x:hover{background:rgba(194,84,84,.12);color:var(--err)}
    .hdr{background:var(--panel);border-bottom:1px solid var(--border);padding:18px 28px}
    .hdr h2{font-size:18px;font-weight:600}
    .hdr p{font-size:13px;color:var(--muted);margin-top:2px}
    .msgs{flex:1;overflow:auto;padding:26px 28px;display:flex;flex-direction:column;gap:18px}
    .msg{max-width:860px}
    .label{font-size:11px;color:var(--muted);letter-spacing:.05em;text-transform:uppercase;margin-bottom:6px}
    .bubble{border-radius:18px;padding:14px 16px;white-space:pre-wrap}
    .u{align-self:flex-end}
    .u .bubble{background:var(--accent);color:#fff;border-radius:18px 18px 4px 18px}
    .a .bubble{background:var(--panel);border:1px solid var(--border);border-radius:18px 18px 18px 4px}
    .foot{border-top:1px solid var(--border);background:var(--panel);padding:18px 28px}
    .row{display:flex;gap:12px;max-width:860px}
    .send{width:56px;height:56px;border-radius:14px;display:flex;align-items:center;justify-content:center}
    .tiny{font-family:"IBM Plex Mono",monospace;font-size:11px;color:var(--muted)}
    .badge{display:inline-flex;align-items:center;gap:8px;font-family:"IBM Plex Mono",monospace;font-size:11px;padding:6px 10px;border-radius:999px;margin-top:12px}
    .bOk{background:rgba(90,138,92,.15);color:var(--ok)}
    .bWarn{background:rgba(196,136,58,.15);color:var(--warn)}
    .bErr{background:rgba(194,84,84,.15);color:var(--err)}
    .bAbs{background:rgba(138,106,170,.15);color:#8a6aaa}
    .src{margin-top:10px;padding-top:10px;border-top:1px solid var(--border)}
    .srcTitle{font-size:11px;color:var(--muted);text-transform:uppercase;letter-spacing:.05em;margin-bottom:8px}
    .srcItem{background:#fff;border:1px solid var(--border);border-radius:10px;padding:10px 12px;margin-bottom:8px}
    .srcDoc{color:var(--accent);font-weight:700;font-size:12px}
    .srcTxt{margin-top:6px;color:#5c4d3a;font-size:12px}
    .overlay{position:fixed;inset:0;background:rgba(250,246,241,.92);display:flex;align-items:center;justify-content:center;z-index:1000}
    .modal{background:var(--panel);border:1px solid var(--border);border-radius:18px;padding:26px;max-width:420px;width:92%;box-shadow:0 18px 60px rgba(0,0,0,.12)}
    .bar{height:8px;background:var(--panel2);border-radius:999px;overflow:hidden;margin-top:12px}
    .fill{height:100%;background:linear-gradient(90deg,var(--accent),#d4886a);width:40%}
    .grid2{display:grid;grid-template-columns:1fr 1fr;gap:10px}
    .stat{background:#fff;border:1px solid var(--border);border-radius:10px;padding:12px;text-align:center}
    .statNum{font-family:"IBM Plex Mono",monospace;font-size:20px;font-weight:700;color:var(--accent)}
    .statLbl{font-size:11px;color:var(--muted);letter-spacing:.05em;text-transform:uppercase}
  </style>
</head>
<body>
  <div id="root"></div>

  <script type="text/babel">
    const { useState, useEffect, useRef } = React;

    // ---------- Utils ----------
    function sleep(ms){ return new Promise(r => setTimeout(r, ms)); }
    function safeJsonParse(text){ try { return JSON.parse(text); } catch { return null; } }

    // ---------- BM25 ----------
    class BM25 {
      constructor(documents, k1=1.5, b=0.75){
        this.k1=k1; this.b=b; this.documents=documents;
        this.N = documents.length;
        this.avgDocLength=0; this.docLengths=[]; this.termFreqs=[]; this.docFreqs={}; this.idf={};
        this._buildIndex();
      }
      _tokenize(text){
        return text.toLowerCase().replace(/[^\w\s]/g,' ').split(/\s+/).filter(t=>t.length>1);
      }
      _buildIndex(){
        let total=0;
        for(const doc of this.documents){
          const tokens=this._tokenize(doc);
          this.docLengths.push(tokens.length);
          total += tokens.length;
          const tf={}; const seen=new Set();
          for(const tok of tokens){
            tf[tok]=(tf[tok]||0)+1;
            if(!seen.has(tok)){ this.docFreqs[tok]=(this.docFreqs[tok]||0)+1; seen.add(tok); }
          }
          this.termFreqs.push(tf);
        }
        this.avgDocLength = this.N>0 ? total/this.N : 0;
        for(const term in this.docFreqs){
          this.idf[term] = Math.log(1 + (this.N - this.docFreqs[term] + 0.5) / (this.docFreqs[term] + 0.5));
        }
      }
      search(query, topK=10){
        const qToks = this._tokenize(query);
        const scores=[];
        for(let i=0;i<this.N;i++){
          let score=0;
          const dl = this.docLengths[i];
          const tf = this.termFreqs[i];
          for(const term of qToks){
            if(tf[term]){
              const termFreq = tf[term];
              const idf = this.idf[term] || 0;
              score += idf * ((termFreq*(this.k1+1))/(termFreq + this.k1*(1-this.b + this.b*(dl/Math.max(this.avgDocLength,1)))));
            }
          }
          scores.push({index:i,score});
        }
        return scores.sort((a,b)=>b.score-a.score).slice(0, topK);
      }
    }

    function cosineSimilarity(a,b){
      const n = Math.min(a.length,b.length);
      let dot=0,na=0,nb=0;
      for(let i=0;i<n;i++){ dot+=a[i]*b[i]; na+=a[i]*a[i]; nb+=b[i]*b[i]; }
      const denom = Math.sqrt(na)*Math.sqrt(nb);
      return denom>0 ? dot/denom : 0;
    }

    function chunkText(text, size=250, overlap=50){
      const words = text.split(/\s+/);
      const chunks=[];
      for(let i=0;i<words.length;i += (size-overlap)){
        const chunk = words.slice(i, i+size).join(' ');
        if(chunk.trim().length>50) chunks.push(chunk);
      }
      return chunks;
    }

    // ---------- Hugging Face error model ----------
    class HFError extends Error {
      constructor({ status, category, model, detail, hint, requestId }){
        super("Hugging Face request failed");
        this.name="HFError";
        this.status=status;
        this.category=category;
        this.model=model;
        this.detail=detail;
        this.hint=hint;
        this.requestId=requestId;
      }
      toUserString(){
        const lines=[];
        lines.push(`HF ${this.status ?? ""} ${this.category ?? "UNKNOWN"}`.trim());
        if(this.model) lines.push(`Model: ${this.model}`);
        if(this.detail) lines.push(`Detail: ${this.detail}`);
        if(this.hint) lines.push(`Fix: ${this.hint}`);
        if(this.requestId) lines.push(`Request-ID: ${this.requestId}`);
        return lines.join("\n");
      }
    }

    function classifyHF(status, detail=""){
      const d = (detail || "").toLowerCase();
      if(status===401) return {cat:"AUTH", hint:"Invalid/expired token. Regenerate it (starts with hf_)."};
      if(status===403){
        if(d.includes("inference") || d.includes("provider") || d.includes("scope") || d.includes("permission")){
          return {cat:"PERMISSION", hint:"Your token is missing Inference permission. In HF token settings, enable: Inference ‚Üí Make calls to Inference Providers."};
        }
        if(d.includes("gated") || d.includes("accept") || d.includes("terms") || d.includes("license")){
          return {cat:"GATED", hint:"Model is gated. Accept the model terms AND enable: Repositories ‚Üí Read access to all public gated repos you can access."};
        }
        return {cat:"PERMISSION", hint:"Forbidden. Usually missing Inference permission or gated-repo read permission."};
      }
      if(status===429) return {cat:"RATE_LIMIT", hint:"Rate limit. Wait, reduce calls/batch size, or upgrade."};
      if(status===503) return {cat:"MODEL_LOADING", hint:"Model is loading. Retry after the estimated time."};
      if(status===400 || status===422) return {cat:"BAD_REQUEST", hint:"Bad request. Payload/parameters may not match the model pipeline."};
      if(status>=500) return {cat:"SERVER", hint:"HF server error. Retry later."};
      return {cat:"UNKNOWN", hint:"Unknown error. Check details."};
    }

    // ---------- HuggingFace API ----------
    class HuggingFaceAPI {
      constructor(apiKey, models){
        this.apiKey = apiKey;
        this.baseUrl = 'https://super-king-a664.misha17031.workers.dev/hf';
        this.embeddingModel = models.embeddingModel;
        this.llmModel = models.llmModel;
        this.nliModel = models.nliModel;
      }

      setModels(models){
        this.embeddingModel = models.embeddingModel;
        this.llmModel = models.llmModel;
        this.nliModel = models.nliModel;
      }

      _headers(){
        return { "Authorization": `Bearer ${this.apiKey}`, "Content-Type": "application/json" };
      }

      formatAnyError(e){
        if(e instanceof HFError) return e.toUserString();
        if(e?.name === "AbortError") return "NETWORK\nDetail: Request timed out\nFix: Try again, or use fewer docs/chunks.";
        if(e?.name === "TypeError") return `NETWORK\nDetail: ${e.message}\nFix: CORS/adblock/VPN can block browser fetch. Try another browser, disable blockers, or run behind a small server proxy.`;
        return `UNKNOWN\nDetail: ${e?.message || String(e)}`;
      }

      async _fetch(model, payload, onStatus){
        const url = `${this.baseUrl}/${model}`;
        const maxAttempts = 8;

        for(let attempt=1; attempt<=maxAttempts; attempt++){
          const controller = new AbortController();
          const timeoutMs = 60000;
          const t = setTimeout(()=>controller.abort(), timeoutMs);

          let resp;
          try{
            resp = await fetch(url, {
              method:"POST",
              headers:this._headers(),
              body:JSON.stringify(payload),
              signal:controller.signal
            });
          } catch(err){
            clearTimeout(t);
            if(attempt === maxAttempts){
              throw err;
            }
            if(onStatus) onStatus(`Network issue‚Ä¶ retrying (${attempt+1}/${maxAttempts})`);
            await sleep(1200*attempt);
            continue;
          } finally {
            clearTimeout(t);
          }

          const requestId =
            resp.headers.get("x-request-id") ||
            resp.headers.get("x-amzn-trace-id") ||
            resp.headers.get("x-correlation-id");

          // Model loading
          if(resp.status === 503){
            let wait=10;
            try{
              const data = await resp.json();
              wait = Number(data?.estimated_time ?? wait);
            } catch {}
            if(onStatus) onStatus(`Model loading (~${Math.ceil(wait)}s)‚Ä¶`);
            await sleep(Math.min(wait*1000, 30000));
            continue;
          }

          // Rate limit
          if(resp.status === 429){
            const retryAfter = Number(resp.headers.get("retry-after") || "0");
            const sleepMs = retryAfter>0 ? retryAfter*1000 : 2000*attempt;
            if(onStatus) onStatus(`Rate limited. Retrying in ${Math.ceil(sleepMs/1000)}s‚Ä¶`);
            await sleep(Math.min(sleepMs, 30000));
            continue;
          }

          if(!resp.ok){
            const raw = await resp.text();
            const j = safeJsonParse(raw);
            const detail = j?.error || j?.message || j?.detail || raw || `HTTP ${resp.status}`;
            const {cat, hint} = classifyHF(resp.status, detail);

            // Hard-stop errors: do not spam retries
            if([401,403,400,422].includes(resp.status) || attempt === maxAttempts){
              throw new HFError({ status: resp.status, category: cat, model, detail, hint, requestId });
            }

            if(onStatus) onStatus(`Error ${resp.status}. Retrying (${attempt+1}/${maxAttempts})‚Ä¶`);
            await sleep(1200*attempt);
            continue;
          }

          const text = await resp.text();
          const json = safeJsonParse(text);
          return json === null ? text : json;
        }

        throw new HFError({ status:null, category:"UNKNOWN", model, detail:"Failed after retries", hint:null, requestId:null });
      }

      async getEmbedding(text, onStatus){
        const out = await this._fetch(this.embeddingModel, { inputs: text, options:{ wait_for_model:true } }, onStatus);
        if(Array.isArray(out) && typeof out[0] === "number") return out;
        if(Array.isArray(out) && Array.isArray(out[0]) && typeof out[0][0] === "number") return out[0];
        throw new HFError({
          status:null, category:"BAD_REQUEST", model:this.embeddingModel,
          detail:`Unexpected embedding response: ${JSON.stringify(out).slice(0,350)}`,
          hint:"Embedding model returned unexpected format. Try another embedding model.",
          requestId:null
        });
      }

      async getEmbeddings(texts, onStatus){
        const out = await this._fetch(this.embeddingModel, { inputs: texts, options:{ wait_for_model:true } }, onStatus);
        if(Array.isArray(out) && Array.isArray(out[0])) return out;
        throw new HFError({
          status:null, category:"BAD_REQUEST", model:this.embeddingModel,
          detail:`Unexpected batch embedding response: ${JSON.stringify(out).slice(0,350)}`,
          hint:"Batch embedding format unexpected. Reduce batch size or change model.",
          requestId:null
        });
      }

      async generateAnswer(context, question, onStatus){
        // Llama 3 Instruct style prompt (works with most llama instruct repos)
        const prompt = `<s>[INST] You are a helpful onboarding assistant. Answer ONLY using the provided context. If the answer is not in the context, say: "I don't have enough information to answer this."\n\nContext:\n${context}\n\nQuestion: ${question} [/INST]`;

        const out = await this._fetch(this.llmModel, {
          inputs: prompt,
          parameters: { max_new_tokens: 500, temperature: 0.1, do_sample: false, return_full_text: false },
          options: { wait_for_model:true }
        }, onStatus);

        if(Array.isArray(out) && out[0]?.generated_text) return out[0].generated_text;
        if(out?.generated_text) return out.generated_text;

        throw new HFError({
          status:null, category:"BAD_REQUEST", model:this.llmModel,
          detail:`Unexpected LLM response: ${JSON.stringify(out).slice(0,350)}`,
          hint:"LLM response format unexpected. The model might be using a different pipeline.",
          requestId:null
        });
      }

      async checkEntailment(premise, hypothesis, onStatus){
        const out = await this._fetch(this.nliModel, { inputs: `${premise} [SEP] ${hypothesis}`, options:{ wait_for_model:true } }, onStatus);
        if(!Array.isArray(out)){
          throw new HFError({
            status:null, category:"BAD_REQUEST", model:this.nliModel,
            detail:`Unexpected NLI response: ${JSON.stringify(out).slice(0,350)}`,
            hint:"NLI response format unexpected. Try a different MNLI model.",
            requestId:null
          });
        }
        const ent = out.find(r => r.label === "ENTAILMENT");
        const con = out.find(r => r.label === "CONTRADICTION");
        return { entailment: ent?.score || 0, contradiction: con?.score || 0 };
      }

      async quickTestModel(modelId, kind){
        // kind: "embedding" | "llm" | "nli"
        if(kind === "embedding"){
          await this._fetch(modelId, { inputs:"test", options:{ wait_for_model:true } });
          return "OK";
        }
        if(kind === "llm"){
          const prompt = "Say OK.";
          const out = await this._fetch(modelId, { inputs: prompt, parameters:{ max_new_tokens: 8, do_sample:false }, options:{ wait_for_model:true } });
          return (Array.isArray(out) ? (out[0]?.generated_text || "OK") : (out?.generated_text || "OK"));
        }
        if(kind === "nli"){
          await this._fetch(modelId, { inputs:"A [SEP] A", options:{ wait_for_model:true } });
          return "OK";
        }
        return "Unknown kind";
      }
    }

    // ---------- App ----------
    function App(){
      const [apiKey, setApiKey] = useState(localStorage.getItem("hf_api_key") || "");
      const [status, setStatus] = useState("idle");
      const [statusMsg, setStatusMsg] = useState("");
      const [documents, setDocuments] = useState([]);
      const [chunks, setChunks] = useState([]);
      const [embeddings, setEmbeddings] = useState([]);
      const [bm25Index, setBm25Index] = useState(null);
      const [messages, setMessages] = useState([]);
      const [input, setInput] = useState("");
      const [processing, setProcessing] = useState(false);
      const [procStatus, setProcStatus] = useState("");
      const [procProgress, setProcProgress] = useState(0);
      const [loading, setLoading] = useState(false);
      const [trustThreshold, setTrustThreshold] = useState(0.5);
      const [hybridLambda, setHybridLambda] = useState(0.5);
      const [topK, setTopK] = useState(5);

      // models (editable)
      const [embeddingModel, setEmbeddingModel] = useState(localStorage.getItem("hf_embedding_model") || "BAAI/bge-large-en-v1.5");
      const [llmModel, setLlmModel] = useState(localStorage.getItem("hf_llm_model") || "meta-llama/Meta-Llama-3-8B-Instruct");
      const [nliModel, setNliModel] = useState(localStorage.getItem("hf_nli_model") || "microsoft/deberta-v3-large-mnli");
      const [testMsg, setTestMsg] = useState("");

      const chatEnd = useRef(null);
      const fileInput = useRef(null);
      const api = useRef(null);
      const timer = useRef(null);

      useEffect(()=>{ chatEnd.current?.scrollIntoView({behavior:"smooth"}); }, [messages, loading]);

      // persist models
      useEffect(()=>{
        localStorage.setItem("hf_embedding_model", embeddingModel);
        localStorage.setItem("hf_llm_model", llmModel);
        localStorage.setItem("hf_nli_model", nliModel);
        if(api.current){
          api.current.setModels({ embeddingModel, llmModel, nliModel });
        }
      }, [embeddingModel, llmModel, nliModel]);

      useEffect(()=>{
        if(apiKey){
          localStorage.setItem("hf_api_key", apiKey);
          api.current = new HuggingFaceAPI(apiKey, { embeddingModel, llmModel, nliModel });
          if(timer.current) clearTimeout(timer.current);
          timer.current = setTimeout(()=>validateKey(), 500);
        } else {
          setStatus("idle"); setStatusMsg("");
        }
        return ()=>{ if(timer.current) clearTimeout(timer.current); };
      }, [apiKey]);

      async function validateKey(){
        if(!apiKey) return;
        if(!apiKey.startsWith("hf_")){
          setStatus("error");
          setStatusMsg('API key should start with "hf_"');
          return;
        }
        setStatus("loading");
        setStatusMsg("Connecting to Hugging Face‚Ä¶ (testing embedding model)");
        try{
          await api.current.getEmbedding("test", (m)=>setStatusMsg(m));
          setStatus("connected");
          setStatusMsg("Ready to use!");
        } catch(e){
          setStatus("error");
          setStatusMsg(api.current.formatAnyError(e));
        }
      }

      function statusDot(){
        if(status==="connected") return {cls:"ok", icon:"‚úì", title:"Connected"};
        if(status==="loading") return {cls:"info", icon:"‚è≥", title:"Connecting‚Ä¶"};
        if(status==="error") return {cls:"err", icon:"‚úï", title:"Error"};
        return {cls:"warn", icon:"‚óã", title:"Waiting‚Ä¶"};
      }

      async function processFile(file){
        const ext = file.name.split(".").pop().toLowerCase();
        if(ext==="pdf"){
          const ab = await file.arrayBuffer();
          const pdf = await pdfjsLib.getDocument({data:ab}).promise;
          const pages=[];
          for(let i=1;i<=pdf.numPages;i++){
            const page = await pdf.getPage(i);
            const content = await page.getTextContent();
            pages.push(content.items.map(it=>it.str).join(" "));
          }
          return pages.join("\n\n");
        }
        if(ext==="docx"){
          const ab = await file.arrayBuffer();
          const result = await mammoth.extractRawText({arrayBuffer:ab});
          return result.value;
        }
        if(ext==="json"){
          return JSON.stringify(JSON.parse(await file.text()), null, 2);
        }
        return await file.text();
      }

      async function handleUpload(fileList){
        if(status!=="connected") return;
        const files = Array.from(fileList);
        setProcessing(true);
        setProcProgress(0);
        setTestMsg("");

        const newDocs=[], newChunks=[];
        for(let i=0;i<files.length;i++){
          setProcStatus(`Reading ${files[i].name}‚Ä¶`);
          try{
            const text = await processFile(files[i]);
            const fileChunks = chunkText(text).map((chunk, idx)=>({ text:chunk, docName:files[i].name, chunkIndex:idx }));
            newDocs.push({ name:files[i].name, chunkCount:fileChunks.length });
            newChunks.push(...fileChunks);
            setProcProgress(((i+1)/files.length)*45);
          } catch(e){
            console.error(e);
          }
        }

        const allChunks = [...chunks, ...newChunks];
        setDocuments(prev => [...prev, ...newDocs]);
        setChunks(allChunks);
        setBm25Index(new BM25(allChunks.map(c=>c.text)));
        setProcProgress(55);

        // embeddings
        const batchSize = 10;
        const nextEmb = [...embeddings];

        for(let i=embeddings.length; i<allChunks.length; i+=batchSize){
          const batch = allChunks.slice(i, Math.min(i+batchSize, allChunks.length));
          setProcStatus(`Embedding ${Math.min(i+batchSize, allChunks.length)}/${allChunks.length}‚Ä¶`);
          try{
            const out = await api.current.getEmbeddings(batch.map(b=>b.text), (m)=>setProcStatus(m));
            nextEmb.push(...out);
          } catch(e){
            // keep app working, but tell user exactly what failed
            const msg = api.current.formatAnyError(e);
            setTestMsg(`Embedding error (used zero vectors for this batch):\n\n${msg}`);
            nextEmb.push(...batch.map(()=>new Array(1024).fill(0)));
          }
          const done = (i - embeddings.length + batch.length);
          const total = Math.max(1, (allChunks.length - embeddings.length));
          setProcProgress(55 + (done/total)*45);
        }

        setEmbeddings(nextEmb);
        setProcessing(false);
      }

      async function hybridSearch(query){
        if(chunks.length===0) return [];
        const bm = bm25Index.search(query, topK*2);
        const bmScores = new Array(chunks.length).fill(0);
        const maxBm = Math.max(...bm.map(r=>r.score), 1);
        bm.forEach(r=>{ bmScores[r.index] = r.score/maxBm; });

        const qEmb = await api.current.getEmbedding(query);
        const vecScores = embeddings.map(e => cosineSimilarity(qEmb, e));
        const maxVec = Math.max(...vecScores, 0.001);

        return chunks.map((chunk, idx)=>({
          chunk, index: idx,
          hybridScore: hybridLambda*bmScores[idx] + (1-hybridLambda)*(vecScores[idx]/maxVec)
        })).sort((a,b)=>b.hybridScore-a.hybridScore).slice(0, topK);
      }

      async function calcTrust(answer, sources){
        const retrieval = sources.reduce((a,s)=>a+s.hybridScore,0)/sources.length;
        let entail=0;
        for(const src of sources.slice(0,2)){
          try{
            const r = await api.current.checkEntailment(src.chunk.text, answer.slice(0,500));
            entail += Math.max(0, r.entailment - r.contradiction*0.5);
          } catch {}
        }
        entail /= Math.min(2, sources.length);

        const ansWords = new Set(answer.toLowerCase().split(/\s+/));
        const srcWords = new Set(sources.flatMap(s => s.chunk.text.toLowerCase().split(/\s+/)));
        const attribution = ansWords.size ? ([...ansWords].filter(w=>srcWords.has(w)).length/ansWords.size) : 0;

        return { overall: 0.3*retrieval + 0.4*entail + 0.3*attribution, retrieval, entailment: entail, attribution };
      }

      function trustBadge(score){
        if(score>=0.7) return {cls:"bOk", label:`High ${(score*100).toFixed(0)}%`};
        if(score>=0.5) return {cls:"bWarn", label:`Medium ${(score*100).toFixed(0)}%`};
        if(score>=0.3) return {cls:"bErr", label:`Low ${(score*100).toFixed(0)}%`};
        return {cls:"bAbs", label:`Abstained ${(score*100).toFixed(0)}%`};
      }

      async function handleSubmit(){
        if(!input.trim() || loading || chunks.length===0) return;
        const q = input.trim();
        setInput("");
        setMessages(prev => [...prev, {type:"user", content:q}]);
        setLoading(true);

        try{
          const results = await hybridSearch(q);
          if(results.length===0){
            setMessages(prev => [...prev, {type:"assistant", content:"No relevant information found.", trust:{overall:0,retrieval:0,entailment:0,attribution:0}, sources:[], abstained:true}]);
          } else {
            const context = results.map((r,i)=>`[Source ${i+1}]\n${r.chunk.text}`).join("\n\n");
            const ans = await api.current.generateAnswer(context, q);
            const trust = await calcTrust(ans, results);
            const abstain = trust.overall < trustThreshold;

            setMessages(prev => [...prev, {
              type:"assistant",
              content: abstain ? "I'm not confident enough to answer this based on the documents." : ans,
              trust,
              sources: results,
              abstained: abstain
            }]);
          }
        } catch(e){
          const msg = api.current.formatAnyError(e);
          setMessages(prev => [...prev, {
            type:"assistant",
            content:`Could not answer due to an API error.\n\n${msg}`,
            trust:{overall:0,retrieval:0,entailment:0,attribution:0},
            sources:[],
            abstained:true
          }]);
        }

        setLoading(false);
      }

      function removeDoc(name){
        setDocuments(prev => prev.filter(d=>d.name!==name));
        const remaining = chunks.filter(c=>c.docName!==name);
        setChunks(remaining);
        if(remaining.length){
          setBm25Index(new BM25(remaining.map(c=>c.text)));
          // best-effort keep embedding alignment:
          setEmbeddings(prev=>{
            const keepIdx = chunks.map((c,i)=>c.docName!==name ? i : -1).filter(i=>i!==-1);
            return keepIdx.map(i=>prev[i]).filter(v=>v!==undefined);
          });
        } else {
          setBm25Index(null);
          setEmbeddings([]);
        }
      }

      async function testModels(){
        if(!api.current) return;
        setTestMsg("Testing model access‚Ä¶");
        try{
          const a = await api.current.quickTestModel(embeddingModel, "embedding");
          const b = await api.current.quickTestModel(llmModel, "llm");
          const c = await api.current.quickTestModel(nliModel, "nli");
          setTestMsg(`Model tests OK:\n- embedding: ${a}\n- llm: ${b}\n- nli: ${c}`);
        } catch(e){
          setTestMsg(api.current.formatAnyError(e));
        }
      }

      const dot = statusDot();
      const ready = status==="connected";

      return (
        <div className="app">
          {processing && (
            <div className="overlay">
              <div className="modal">
                <h3 style={{marginBottom:6}}>Processing documents</h3>
                <div className="help" style={{marginBottom:10}}>{procStatus}</div>
                <div className="bar"><div className="fill" style={{width:`${procProgress}%`}} /></div>
              </div>
            </div>
          )}

          <aside className="side">
            <div className="logo">
              <div className="mark">M</div>
              <div>
                <h1>MAISA</h1>
                <div className="sub">Onboarding Assistant</div>
              </div>
            </div>

            <div className="sec">
              <div className="secTitle">API configuration</div>
              <label>Hugging Face token</label>
              <input
                type="password"
                value={apiKey}
                onChange={(e)=>setApiKey(e.target.value)}
                placeholder="hf_xxxxxxxxxxxx"
              />
              <div className="help" style={{marginTop:8}}>
                Token settings that usually fix 403 errors:
                <br/>‚Ä¢ Inference ‚Üí <b>Make calls to Inference Providers</b>
                <br/>‚Ä¢ Repositories ‚Üí <b>Read access to all public gated repos you can access</b>
                <br/>Token page: <a href="https://huggingface.co/settings/tokens" target="_blank" rel="noreferrer">huggingface.co</a>
              </div>

              {apiKey && (
                <div className="status" style={{marginTop:12}}>
                  <div className="statusRow">
                    <div className={`dot ${dot.cls}`}>{dot.icon}</div>
                    <div style={{fontWeight:700}}>{dot.title}</div>
                  </div>
                  <div className="statusMsg">{statusMsg}</div>
                </div>
              )}
            </div>

            <div className="sec">
              <div className="secTitle">Models</div>

              <label>Embedding model</label>
              <input type="text" value={embeddingModel} onChange={(e)=>setEmbeddingModel(e.target.value)} />

              <div style={{height:10}} />

              <label>LLM model (Llama)</label>
              <input type="text" value={llmModel} onChange={(e)=>setLlmModel(e.target.value)} />
              <div className="help" style={{marginTop:6}}>
                Tip: if you want Llama 4, paste the exact HF model id here (the collection name alone is not a model id).
              </div>

              <div style={{height:10}} />

              <label>NLI model</label>
              <input type="text" value={nliModel} onChange={(e)=>setNliModel(e.target.value)} />

              <div style={{display:"flex", gap:10, marginTop:10}}>
                <button className="btn" onClick={testModels} disabled={!apiKey}>Test access</button>
                <button className="btn" onClick={validateKey} disabled={!apiKey}>Re-check token</button>
              </div>

              {testMsg && (
                <div className="status" style={{marginTop:10}}>
                  <div className="statusMsg">{testMsg}</div>
                </div>
              )}
            </div>

            <div className="sec">
              <div className="secTitle">Documents</div>
              <div
                className={`drop ${!ready ? "disabled" : ""}`}
                onClick={()=> ready && fileInput.current?.click()}
                onDragOver={(e)=>{ e.preventDefault(); if(ready) e.currentTarget.classList.add("dragover"); }}
                onDragLeave={(e)=>{ e.currentTarget.classList.remove("dragover"); }}
                onDrop={(e)=>{ e.preventDefault(); e.currentTarget.classList.remove("dragover"); if(ready) handleUpload(e.dataTransfer.files); }}
              >
                <div style={{fontWeight:700}}>Drop files or click to upload</div>
                <div className="help">PDF, DOCX, TXT, JSON</div>
              </div>

              <input
                ref={fileInput}
                type="file"
                multiple
                accept=".pdf,.docx,.txt,.md,.json"
                style={{display:"none"}}
                onChange={(e)=> ready && e.target.files?.length && handleUpload(e.target.files)}
              />

              {documents.length>0 && (
                <div className="list" style={{marginTop:10}}>
                  {documents.map((d,i)=>(
                    <div className="item" key={i}>
                      <div>
                        <div className="name" title={d.name}>{d.name}</div>
                        <div className="meta">{d.chunkCount} chunks</div>
                      </div>
                      <button className="x" onClick={()=>removeDoc(d.name)}>‚úï</button>
                    </div>
                  ))}
                </div>
              )}
            </div>

            {chunks.length>0 && (
              <div className="sec">
                <div className="secTitle">Index stats</div>
                <div className="grid2">
                  <div className="stat">
                    <div className="statNum">{documents.length}</div>
                    <div className="statLbl">Docs</div>
                  </div>
                  <div className="stat">
                    <div className="statNum">{chunks.length}</div>
                    <div className="statLbl">Chunks</div>
                  </div>
                </div>
              </div>
            )}

            <div className="sec">
              <div className="secTitle">Settings</div>

              <div className="help">Trust threshold: <span className="tiny">{trustThreshold.toFixed(2)}</span></div>
              <input type="range" min="0" max="1" step="0.05" value={trustThreshold}
                onChange={(e)=>setTrustThreshold(parseFloat(e.target.value))} />

              <div style={{height:10}} />

              <div className="help">Hybrid Œª: <span className="tiny">{hybridLambda.toFixed(2)}</span></div>
              <input type="range" min="0" max="1" step="0.05" value={hybridLambda}
                onChange={(e)=>setHybridLambda(parseFloat(e.target.value))} />

              <div style={{height:10}} />

              <div className="help">Top-K: <span className="tiny">{topK}</span></div>
              <input type="range" min="3" max="10" step="1" value={topK}
                onChange={(e)=>setTopK(parseInt(e.target.value,10))} />
            </div>
          </aside>

          <main className="main">
            <header className="hdr">
              <h2>Ask about your documents</h2>
              <p>Shows exact HF error category + fix when something fails.</p>
            </header>

            <div className="msgs">
              {messages.length===0 ? (
                <div style={{textAlign:"center", padding:"60px 16px"}}>
                  <div style={{fontSize:44, marginBottom:12}}>üìÑ</div>
                  <div style={{fontSize:18, fontWeight:700, marginBottom:6}}>No messages yet</div>
                  <div className="help">
                    {!ready ? "Enter a token and fix permissions if needed." : chunks.length===0 ? "Upload documents first." : "Ask a question!"}
                  </div>
                </div>
              ) : (
                messages.map((m,i)=>(
                  <div key={i} className={`msg ${m.type==="user" ? "u" : "a"}`}>
                    <div className="label">{m.type==="user" ? "You" : "MAISA"}</div>
                    <div className="bubble">
                      {m.content}
                      {m.type==="assistant" && m.trust && (
                        <>
                          <div className={`badge ${trustBadge(m.trust.overall).cls}`}>
                            {trustBadge(m.trust.overall).label}
                            <span className="tiny">
                              R:{Math.round(m.trust.retrieval*100)}% E:{Math.round(m.trust.entailment*100)}% A:{Math.round(m.trust.attribution*100)}%
                            </span>
                          </div>

                          {m.sources?.length>0 && (
                            <div className="src">
                              <div className="srcTitle">Sources</div>
                              {m.sources.slice(0,3).map((s,j)=>(
                                <div key={j} className="srcItem">
                                  <div className="srcDoc">{s.chunk.docName}</div>
                                  <div className="srcTxt">{s.chunk.text.slice(0,220)}‚Ä¶</div>
                                </div>
                              ))}
                            </div>
                          )}
                        </>
                      )}
                    </div>
                  </div>
                ))
              )}

              {loading && (
                <div className="msg a">
                  <div className="label">MAISA</div>
                  <div className="bubble">Searching‚Ä¶</div>
                </div>
              )}

              <div ref={chatEnd} />
            </div>

            <footer className="foot">
              <div className="row">
                <textarea
                  value={input}
                  onChange={(e)=>setInput(e.target.value)}
                  onKeyDown={(e)=>{ if(e.key==="Enter" && !e.shiftKey){ e.preventDefault(); handleSubmit(); } }}
                  placeholder={!ready ? "Connect token first‚Ä¶" : chunks.length===0 ? "Upload documents first‚Ä¶" : "Ask a question‚Ä¶"}
                  disabled={!ready || chunks.length===0 || loading}
                />
                <button className="btn btnPrimary send" onClick={handleSubmit}
                  disabled={!ready || chunks.length===0 || loading || !input.trim()}>
                  ‚Üí
                </button>
              </div>
            </footer>
          </main>
        </div>
      );
    }

    ReactDOM.createRoot(document.getElementById("root")).render(<App />);
  </script>
</body>
</html>
